{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Python Neural Network Example\n",
    "\n",
    "This example comes from [Andrew Trask's](http://iamtrask.github.io/2015/07/12/basic-python-network/) blog.\n",
    "\n",
    "We start with the original source, and then refactor it to better reflect the network structure and modularity\n",
    "of the layers.\n",
    "\n",
    "First we start out with a sample problem; training to implement this boolean function of 3 inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n",
      "\n",
      "Output:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input features and desired output\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "print(\"Input:\\n%s\" % X)\n",
    "print(\"\\nOutput:\\n%s\" % y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the intial code as presented *a 9 line python neural network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[  2.57918557e-01   9.21504930e-01   9.97693994e-01   9.18618144e-01]\n",
      " [  9.55758425e-01   1.67356634e-02   9.53851147e-01   9.99403861e-01]\n",
      " [  9.01425533e-01   5.58647232e-02   5.96264330e-01   2.95224215e-01]\n",
      " [  9.98243757e-01   8.57795042e-05   6.59045947e-02   9.84180673e-01]]\n",
      "[[ 0.00972044]\n",
      " [ 0.98582196]\n",
      " [ 0.99442382]\n",
      " [ 0.01366351]]\n"
     ]
    }
   ],
   "source": [
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "for j in range(10000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterize the number of nodes in the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[  3.29861707e-01   4.87333065e-01   9.28959058e-01   6.24234836e-01\n",
      "    4.75311182e-02   9.47274097e-01]\n",
      " [  6.84175162e-01   8.58767574e-02   6.96815740e-02   6.42400971e-02\n",
      "    9.38153342e-05   8.21921132e-01]\n",
      " [  6.21704258e-02   1.01912036e-01   9.99760359e-01   9.17550475e-02\n",
      "    9.42373607e-01   7.49117964e-01]\n",
      " [  2.25857446e-01   1.10903066e-02   9.59833695e-01   4.15745844e-03\n",
      "    2.98289076e-02   4.34098123e-01]]\n",
      "[[ 0.00868254]\n",
      " [ 0.98998334]\n",
      " [ 0.99058551]\n",
      " [ 0.0091875 ]]\n"
     ]
    }
   ],
   "source": [
    "inputs = 3\n",
    "hidden = 6\n",
    "outputs = 1\n",
    "\n",
    "syn0 = 2*np.random.random((inputs, hidden)) - 1\n",
    "syn1 = 2*np.random.random((hidden, outputs)) - 1\n",
    "for j in range(10000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factoring the sigmoid function and it's derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34394513]\n",
      " [ 0.63121779]\n",
      " [ 0.67397988]\n",
      " [-0.35125098]]\n",
      "[[-0.03724754]\n",
      " [ 0.04589352]\n",
      " [ 0.05385622]\n",
      " [-0.05586488]]\n",
      "[[-0.02054541]\n",
      " [ 0.02542788]\n",
      " [ 0.029888  ]\n",
      " [-0.03060701]]\n",
      "[[-0.01529301]\n",
      " [ 0.01910957]\n",
      " [ 0.02244183]\n",
      " [-0.02290625]]\n",
      "[[-0.01256785]\n",
      " [ 0.01583408]\n",
      " [ 0.01857342]\n",
      " [-0.01893238]]\n",
      "[[-0.01085267]\n",
      " [ 0.01376791]\n",
      " [ 0.01613093]\n",
      " [-0.01643228]]\n",
      "[[-0.00965419]\n",
      " [ 0.01231977]\n",
      " [ 0.01441831]\n",
      " [-0.01468316]]\n",
      "[[-0.00875973]\n",
      " [ 0.01123549]\n",
      " [ 0.01313583]\n",
      " [-0.01337529]]\n",
      "[[-0.00806117]\n",
      " [ 0.01038596]\n",
      " [ 0.01213104]\n",
      " [-0.01235171]]\n",
      "[[-0.00749719]\n",
      " [ 0.00969798]\n",
      " [ 0.01131743]\n",
      " [-0.01152352]]\n",
      "Output After Training:\n",
      "[[ 6.58089673 -1.67118631  3.55879544  0.31293784  4.48448712  3.46793134]\n",
      " [ 6.30458744  4.69220161 -1.47520456  0.34485138 -2.65903204  3.95088554]\n",
      " [-2.37198712 -0.21481039  0.35361032  0.5496883   1.08767116 -5.65736125]]\n",
      "[[ 11.63749313]\n",
      " [ -4.84379727]\n",
      " [ -2.3102205 ]\n",
      " [  0.59174479]\n",
      " [ -3.70706066]\n",
      " [ -7.49750063]]\n",
      "[[ 0.08533451  0.4464974   0.5874911   0.63406212  0.74794101  0.00347973]\n",
      " [ 0.98078364  0.98876411  0.24571727  0.70982553  0.17202423  0.15362371]\n",
      " [ 0.98535494  0.13170267  0.98039909  0.70320765  0.99621203  0.10070493]\n",
      " [ 0.99997283  0.94300932  0.91961998  0.76985152  0.94849117  0.85338999]]\n",
      "[[ 0.0070306 ]\n",
      " [ 0.99087288]\n",
      " [ 0.98935755]\n",
      " [ 0.01083686]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "syn0 = 2*np.random.random((inputs, hidden)) - 1\n",
    "syn1 = 2*np.random.random((hidden, outputs)) - 1\n",
    "for j in range(10000):\n",
    "    l1 = sigmoid(np.dot(X,syn0))\n",
    "    l2 = sigmoid(np.dot(l1,syn1))\n",
    "    # Display errors every 1000 trials\n",
    "    if j % 1000 == 0:\n",
    "        print(y - l2)\n",
    "    l2_delta = (y - l2) * sigmoid_prime(l2)\n",
    "    l1_delta = l2_delta.dot(syn1.T) * sigmoid_prime(l1)\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(syn0)\n",
    "print(syn1)\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor each Layer into a class to be more DRY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, n, m, sigmoid=True):\n",
    "        \"\"\"\n",
    "        Define an n => m node weighted layer.\n",
    "        \n",
    "        We accept n input features, and compute m output nodes.\n",
    "        \n",
    "        Applies a sigmoid function to the output by default.\n",
    "        \"\"\"\n",
    "        # (n x m) weights\n",
    "        # The ith column represents the weights of the inputs\n",
    "        # to derive the ith output [1..m] via weighted sum.\n",
    "        self.weights = np.random.normal(0, m ** -0.5, (n, m))\n",
    "        self.sigmoid = sigmoid\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Takes some number, k, of input samples (rows) of n inputs each.\n",
    "        \n",
    "        Each output row is the list of m output node values for the\n",
    "        corresponding input row - a (k x m) matrix.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        # (k x n) . (n x m) => (k x m)\n",
    "        self.outputs = np.dot(inputs, self.weights)\n",
    "        if self.sigmoid:\n",
    "            self.outputs = sigmoid(self.outputs)\n",
    "        return self.outputs\n",
    "    \n",
    "    def backward(self, output_errors, learning_rate):\n",
    "        \"\"\"\n",
    "        Propagate error terms from outputs back to inputs.\n",
    "        \n",
    "        output_errors is a list of k error outputs (k x m) matrix.\n",
    "        \n",
    "        Returns the error term for the previous layer - a\n",
    "        (k x n) matrix.\n",
    "        \n",
    "        As a side-effect, the weights of this layer are updated.\n",
    "        \"\"\"\n",
    "        if self.sigmoid:\n",
    "            output_errors = output_errors * sigmoid_prime(self.outputs)\n",
    "        input_errors = output_errors.dot(self.weights.T)\n",
    "        self.weights += learning_rate * np.dot(self.inputs.T, output_errors)\n",
    "        return input_errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `Layer` class instances to organize a training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46804683]\n",
      " [ 0.54988525]\n",
      " [ 0.54659366]\n",
      " [-0.43679974]]\n",
      "[[-0.04281892]\n",
      " [ 0.04455356]\n",
      " [ 0.04293979]\n",
      " [-0.04800706]]\n",
      "[[-0.02356408]\n",
      " [ 0.02463439]\n",
      " [ 0.02374855]\n",
      " [-0.02636336]]\n",
      "[[-0.01763946]\n",
      " [ 0.01848655]\n",
      " [ 0.0178312 ]\n",
      " [-0.01972262]]\n",
      "[[-0.01456724]\n",
      " [ 0.01529431]\n",
      " [ 0.01475734]\n",
      " [-0.016283  ]]\n",
      "[[-0.01262948]\n",
      " [ 0.01327905]\n",
      " [ 0.01281578]\n",
      " [-0.01411499]]\n",
      "[[-0.01127188]\n",
      " [ 0.01186615]\n",
      " [ 0.01145389]\n",
      " [-0.0125968 ]]\n",
      "[[-0.01025597]\n",
      " [ 0.01080824]\n",
      " [ 0.01043373]\n",
      " [-0.01146112]]\n",
      "[[-0.00946057]\n",
      " [ 0.00997951]\n",
      " [ 0.00963427]\n",
      " [-0.01057218]]\n",
      "[[-0.00881689]\n",
      " [ 0.00930853]\n",
      " [ 0.00898679]\n",
      " [-0.00985296]]\n",
      "Output After Training:\n",
      "[[ 2.21817204  5.78599737 -3.49642226  2.41612497  2.13018973  4.23393599]\n",
      " [ 2.06550783  5.85352782 -3.58215081 -3.0271495  -1.48930045  4.14233137]\n",
      " [-3.34340136 -2.35605255  1.04267721 -1.55560375  1.14076067 -6.39847985]]\n",
      "[[-4.23764058]\n",
      " [ 8.30156058]\n",
      " [-4.75495957]\n",
      " [ 2.81350375]\n",
      " [-3.06121008]\n",
      " [-8.63364816]]\n",
      "[[ 0.03411284  0.08658659  0.73936349  0.17427923  0.75781812  0.00166138]\n",
      " [ 0.21791077  0.97061559  0.07313747  0.01012343  0.41374094  0.09482141]\n",
      " [ 0.24504462  0.96862712  0.07916579  0.70276667  0.9634176   0.10298103]\n",
      " [ 0.71915453  0.99990706  0.00238573  0.10278813  0.8558997   0.87844401]]\n",
      "[[ 0.00828321]\n",
      " [ 0.99124803]\n",
      " [ 0.99155044]\n",
      " [ 0.00925674]]\n"
     ]
    }
   ],
   "source": [
    "syn0 = Layer(inputs, hidden)\n",
    "syn1 = Layer(hidden, outputs)\n",
    "\n",
    "for j in range(10000):\n",
    "    l1 = syn0.forward(X)\n",
    "    l2 = syn1.forward(l1)\n",
    "    l2_error = y - l2\n",
    "    # Display errors every 1000 trials\n",
    "    if j % 1000 == 0:\n",
    "        print(l2_error)\n",
    "    l1_error = syn1.backward(l2_error)\n",
    "    syn0.backward(l1_error)\n",
    "    \n",
    "print(\"Output After Training:\")\n",
    "print(syn0.weights)\n",
    "print(syn1.weights)\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Network class to train a multi-layer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, *nodes, learning_rate=0.5):\n",
    "        \"\"\"\n",
    "        Create a multi-layer network.  Arguments are the number of layers in each\n",
    "        layer from input through output.\n",
    "        \"\"\"\n",
    "        self.layers = [Layer(nodes[i], nodes[i + 1]) for i in range(len(nodes) - 1)]\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def train(self, inputs, outputs, iterations=10000, learning_rate=None):\n",
    "        if learning_rate is not None:\n",
    "            self.learning_rate = learning_rate\n",
    "        for i in range(iterations):\n",
    "            errors = self.train_once(inputs, outputs)\n",
    "            if i % 1000 == 0:\n",
    "                print(errors)\n",
    "\n",
    "    def train_once(self, inputs, outputs):\n",
    "        # Run forward\n",
    "        inputs = self.run(inputs)\n",
    "        \n",
    "        # Back-propogate errors\n",
    "        output_errors = outputs - inputs\n",
    "        \n",
    "        errors = output_errors\n",
    "        for layer in self.layers[::-1]:\n",
    "            errors = layer.backward(errors, learning_rate=self.learning_rate)\n",
    "\n",
    "        return output_errors\n",
    "    \n",
    "    def run(self, inputs):\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\\n\".join([\"Layer %d:\\n%s\" % (i, layer.weights) for i, layer in enumerate(self.layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18578175]\n",
      " [ 0.82067767]\n",
      " [ 0.81755938]\n",
      " [-0.17793474]]\n",
      "[[-0.50025766]\n",
      " [ 0.50548572]\n",
      " [ 0.49391415]\n",
      " [-0.49742329]]\n",
      "[[-0.47780446]\n",
      " [ 0.50251536]\n",
      " [ 0.4801639 ]\n",
      " [-0.49519774]]\n",
      "[[-0.29817122]\n",
      " [ 0.38536646]\n",
      " [ 0.35736329]\n",
      " [-0.42419254]]\n",
      "[[-0.13784236]\n",
      " [ 0.17356422]\n",
      " [ 0.16469592]\n",
      " [-0.19224731]]\n",
      "[[-0.08401498]\n",
      " [ 0.10276179]\n",
      " [ 0.09793975]\n",
      " [-0.11239353]]\n",
      "[[-0.06260451]\n",
      " [ 0.07560252]\n",
      " [ 0.0721675 ]\n",
      " [-0.08219357]]\n",
      "[[-0.05117485]\n",
      " [ 0.06134181]\n",
      " [ 0.05860381]\n",
      " [-0.06645194]]\n",
      "[[-0.04397995]\n",
      " [ 0.05245183]\n",
      " [ 0.05013765]\n",
      " [-0.05668246]]\n",
      "[[-0.03897969]\n",
      " [ 0.04631438]\n",
      " [ 0.04428796]\n",
      " [-0.04995853]]\n",
      "[[ 0.03527101]\n",
      " [ 0.95821543]\n",
      " [ 0.96003205]\n",
      " [ 0.04500722]]\n",
      "Layer 0:\n",
      "[[ 4.1547118   2.53523042 -0.37744838 -2.79234374 -0.0184172  -4.97231585]\n",
      " [-3.04860579 -3.80911928  1.18785961 -2.59016786 -1.03111899 -5.0762254 ]\n",
      " [ 1.5004911  -1.26494153  0.46167019  4.13969323  0.12702238  1.76406609]]\n",
      "\n",
      "Layer 1:\n",
      "[[-4.62067983]\n",
      " [ 4.59243842]\n",
      " [-0.76097149]\n",
      " [ 5.47028807]\n",
      " [ 0.99607044]\n",
      " [-7.01515563]]\n"
     ]
    }
   ],
   "source": [
    "n = NeuralNetwork(inputs, hidden, outputs)\n",
    "n.train(X, y, learning_rate=.1)\n",
    "print(n.run(X))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
