{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Python Neural Network Example\n",
    "\n",
    "This example comes from [Andry Trask's](http://iamtrask.github.io/2015/07/12/basic-python-network/) blog.\n",
    "\n",
    "We start with the original source, and then refactor it to better reflect the network structure and modularity\n",
    "of the layers.\n",
    "\n",
    "First we start out with a sample problem; training to implement this boolean function of 3 inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n",
      "\n",
      "Output:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input features and desired output\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "print(\"Input:\\n%s\" % X)\n",
    "print(\"\\nOutput:\\n%s\" % y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the intial code as presented *a 9 line python neural network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[  8.55114497e-01   1.80588202e-01   7.27012227e-01   6.03414158e-01]\n",
      " [  9.99846808e-01   9.37900800e-01   9.75790495e-01   2.46398533e-02]\n",
      " [  4.26092650e-02   2.83578519e-04   9.79447142e-01   2.18868093e-02]\n",
      " [  9.80086286e-01   1.90686030e-02   9.98615422e-01   3.71387120e-04]]\n",
      "[[ 0.00521183]\n",
      " [ 0.98918934]\n",
      " [ 0.98715071]\n",
      " [ 0.01437938]]\n"
     ]
    }
   ],
   "source": [
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "for j in range(10000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterize the number of nodes in the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[ 0.13145509  0.25543757  0.86541247  0.81829263  0.3741695   0.42095258]\n",
      " [ 0.96775253  0.00358605  0.11485183  0.17155396  0.04266259  0.00639713]\n",
      " [ 0.9806165   0.84593094  0.99919242  0.99721182  0.66397542  0.84943384]\n",
      " [ 0.99990032  0.05446175  0.96148983  0.9426812   0.12837519  0.04758618]]\n",
      "[[ 0.00562359]\n",
      " [ 0.99163764]\n",
      " [ 0.99154173]\n",
      " [ 0.01014183]]\n"
     ]
    }
   ],
   "source": [
    "inputs = 3\n",
    "hidden = 6\n",
    "outputs = 1\n",
    "\n",
    "syn0 = 2*np.random.random((inputs, hidden)) - 1\n",
    "syn1 = 2*np.random.random((hidden, outputs)) - 1\n",
    "for j in range(10000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factoring the sigmoid function and it's derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.53036947]\n",
      " [ 0.47419884]\n",
      " [ 0.46304225]\n",
      " [-0.532378  ]]\n",
      "[[-0.04664108]\n",
      " [ 0.04872763]\n",
      " [ 0.0477411 ]\n",
      " [-0.03931221]]\n",
      "[[-0.02652521]\n",
      " [ 0.02648729]\n",
      " [ 0.02737482]\n",
      " [-0.02230832]]\n",
      "[[-0.02026229]\n",
      " [ 0.01982997]\n",
      " [ 0.02098207]\n",
      " [-0.01705751]]\n",
      "[[-0.01697022]\n",
      " [ 0.01639875]\n",
      " [ 0.01760939]\n",
      " [-0.01430092]]\n",
      "[[-0.01487057]\n",
      " [ 0.01423898]\n",
      " [ 0.01545327]\n",
      " [-0.01254304]]\n",
      "[[-0.01338594]\n",
      " [ 0.01272685]\n",
      " [ 0.01392612]\n",
      " [-0.01129985]]\n",
      "[[-0.01226629]\n",
      " [ 0.01159539]\n",
      " [ 0.01277287]\n",
      " [-0.01036199]]\n",
      "[[-0.01138374]\n",
      " [ 0.0107093 ]\n",
      " [ 0.01186285]\n",
      " [-0.00962248]]\n",
      "[[-0.0106653 ]\n",
      " [ 0.00999197]\n",
      " [ 0.01112139]\n",
      " [-0.00902027]]\n",
      "Output After Training:\n",
      "[[ 6.17520303  5.15374032 -3.95911529]\n",
      " [-6.27232511 -4.94450224  3.85133366]\n",
      " [-3.19630462  2.65492189 -2.17548783]]\n",
      "[[ 11.12251765]\n",
      " [ -6.05455807]\n",
      " [  6.1899009 ]]\n",
      "[[  3.93055436e-02   9.34312781e-01   1.01975300e-01]\n",
      " [  7.72343960e-05   9.19901814e-02   8.42351857e-01]\n",
      " [  9.51611003e-01   9.99593949e-01   2.16202356e-03]\n",
      " [  3.57978314e-02   9.46045267e-01   9.25199609e-02]]\n",
      "[[ 0.01006649]\n",
      " [ 0.99060306]\n",
      " [ 0.9894971 ]\n",
      " [ 0.00851815]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "syn0 = 2*np.random.random((inputs, hidden)) - 1\n",
    "syn1 = 2*np.random.random((hidden, outputs)) - 1\n",
    "for j in range(10000):\n",
    "    l1 = sigmoid(np.dot(X,syn0))\n",
    "    l2 = sigmoid(np.dot(l1,syn1))\n",
    "    # Display errors every 1000 trials\n",
    "    if j % 1000 == 0:\n",
    "        print(y - l2)\n",
    "    l2_delta = (y - l2) * sigmoid_prime(l2)\n",
    "    l1_delta = l2_delta.dot(syn1.T) * sigmoid_prime(l1)\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(syn0)\n",
    "print(syn1)\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor each Layer into a class to be more DRY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, n, m, sigmoid=True):\n",
    "        \"\"\"\n",
    "        Define an n => m node weighted layer.\n",
    "        \n",
    "        We accept n input features, and compute m output nodes.\n",
    "        \n",
    "        Applies a sigmoid function to the output by default.\n",
    "        \"\"\"\n",
    "        # (n x m) weights\n",
    "        # The ith column represents the weights of the inputs\n",
    "        # to derive the ith output [1..m] via weighted sum.\n",
    "        self.weights = 2 * np.random.random((n, m)) - 1\n",
    "        self.sigmoid = sigmoid\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Takes some number, k, of input samples (rows) of n inputs each.\n",
    "        \n",
    "        Each output row is the list of m output node values for the\n",
    "        corresponding input row - a (k x m) matrix.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        # (k x n) . (n x m) => (k x m)\n",
    "        self.outputs = np.dot(inputs, self.weights)\n",
    "        if self.sigmoid:\n",
    "            self.outputs = sigmoid(self.outputs)\n",
    "        return self.outputs\n",
    "    \n",
    "    def backward(self, output_errors):\n",
    "        \"\"\"\n",
    "        Propogate error terms from outputs back to inputs.\n",
    "        \n",
    "        output_errors is a list of k error outputs (k x m) matrix.\n",
    "        \n",
    "        Returns the error term for the previous layer - a\n",
    "        (k x n) matrix.\n",
    "        \n",
    "        As a side-effect, the weights of this layer are updated.\n",
    "        \"\"\"\n",
    "        if self.sigmoid:\n",
    "            output_errors = output_errors * sigmoid_prime(self.outputs)\n",
    "        input_errors = output_errors.dot(self.weights.T)\n",
    "        self.weights += np.dot(self.inputs.T, output_errors)\n",
    "        return input_errors\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `Layer` class instances to organize a training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50498807]\n",
      " [ 0.55807692]\n",
      " [ 0.38318375]\n",
      " [-0.5621711 ]]\n",
      "[[-0.03335727]\n",
      " [ 0.04587461]\n",
      " [ 0.04671861]\n",
      " [-0.05682241]]\n",
      "[[-0.01837836]\n",
      " [ 0.025517  ]\n",
      " [ 0.02738914]\n",
      " [-0.03275339]]\n",
      "[[-0.01376553]\n",
      " [ 0.01923011]\n",
      " [ 0.02111858]\n",
      " [-0.02513282]]\n",
      "[[-0.01137163]\n",
      " [ 0.01595154]\n",
      " [ 0.01777302]\n",
      " [-0.02109465]]\n",
      "[[-0.00986068]\n",
      " [ 0.01387434]\n",
      " [ 0.01562106]\n",
      " [-0.01850654]]\n",
      "[[-0.00880152]\n",
      " [ 0.01241387]\n",
      " [ 0.01409084]\n",
      " [-0.01667057]]\n",
      "[[-0.00800859]\n",
      " [ 0.01131782]\n",
      " [ 0.01293208]\n",
      " [-0.01528274]]\n",
      "[[-0.00738753]\n",
      " [ 0.0104576 ]\n",
      " [ 0.01201585]\n",
      " [-0.01418691]]\n",
      "[[-0.0068848 ]\n",
      " [ 0.00976004]\n",
      " [ 0.01126814]\n",
      " [-0.01329368]]\n",
      "Output After Training:\n",
      "[[-4.60854275  5.49316519 -1.33387205  3.47998052  1.43228555 -5.51970359]\n",
      " [-4.93891888 -6.96242521  0.48092396 -1.075712   -0.11942778  3.41726649]\n",
      " [ 1.29813543 -2.49734614 -0.75119578  0.06232811 -0.02589833 -1.39597961]]\n",
      "[[ -5.95787557]\n",
      " [ 10.27050811]\n",
      " [  0.96643355]\n",
      " [ -3.93578204]\n",
      " [ -1.65376938]\n",
      " [  7.05509592]]\n",
      "[[  7.85519853e-01   7.60449167e-02   3.20560635e-01   5.15574812e-01\n",
      "    4.93526495e-01   1.98457448e-01]\n",
      " [  2.55613984e-02   7.79211334e-05   4.32840453e-01   2.66320366e-01\n",
      "    4.63730691e-01   8.83012632e-01]\n",
      " [  3.52164064e-02   9.52384152e-01   1.10557580e-01   9.71866786e-01\n",
      "    8.03193681e-01   9.91166401e-04]\n",
      " [  2.61373565e-04   1.85858626e-02   1.67404734e-01   9.21765199e-01\n",
      "    7.83628591e-01   2.93578020e-02]]\n",
      "[[ 0.00646787]\n",
      " [ 0.99081935]\n",
      " [ 0.98935632]\n",
      " [ 0.01254839]]\n"
     ]
    }
   ],
   "source": [
    "syn0 = Layer(inputs, hidden)\n",
    "syn1 = Layer(hidden, outputs)\n",
    "\n",
    "for j in range(10000):\n",
    "    l1 = syn0.forward(X)\n",
    "    l2 = syn1.forward(l1)\n",
    "    l2_error = y - l2\n",
    "    # Display errors every 1000 trials\n",
    "    if j % 1000 == 0:\n",
    "        print(l2_error)\n",
    "    l1_error = syn1.backward(l2_error)\n",
    "    syn0.backward(l1_error)\n",
    "    \n",
    "print(\"Output After Training:\")\n",
    "print(syn0.weights)\n",
    "print(syn1.weights)\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Network class to train a multi-layer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, *nodes):\n",
    "        \"\"\"\n",
    "        Create a multi-layer network.  Arguments are the number of layers in each\n",
    "        layer from input through output.\n",
    "        \"\"\"\n",
    "        self.layers = [Layer(nodes[i], nodes[i + 1]) for i in range(len(nodes) - 1)]\n",
    "        \n",
    "    def train(self, inputs, outputs, iterations=10000):\n",
    "        for i in range(iterations):\n",
    "            errors = self.train_once(inputs, outputs)\n",
    "            if i % 1000 == 0:\n",
    "                print(errors)\n",
    "            \n",
    "    def train_once(self, inputs, outputs):\n",
    "        # Run forward\n",
    "        inputs = self.run(inputs)\n",
    "        \n",
    "        # Back-propogate errors\n",
    "        output_errors = outputs - inputs\n",
    "        \n",
    "        errors = output_errors\n",
    "        for layer in self.layers[::-1]:\n",
    "            errors = layer.backward(errors)\n",
    "\n",
    "        return output_errors\n",
    "    \n",
    "    def run(self, inputs):\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\\n\".join([\"Layer %d:\\n%s\" % (i, layer.weights) for i, layer in enumerate(self.layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.31877264]\n",
      " [ 0.62053412]\n",
      " [ 0.70381587]\n",
      " [-0.35101251]]\n",
      "[[-0.03794456]\n",
      " [ 0.03687753]\n",
      " [ 0.04630621]\n",
      " [-0.04704316]]\n",
      "[[-0.02208775]\n",
      " [ 0.0215292 ]\n",
      " [ 0.026338  ]\n",
      " [-0.02678495]]\n",
      "[[-0.01676477]\n",
      " [ 0.01644009]\n",
      " [ 0.0197934 ]\n",
      " [-0.0201897 ]]\n",
      "[[-0.01393031]\n",
      " [ 0.01373327]\n",
      " [ 0.01634623]\n",
      " [-0.0167206 ]]\n",
      "[[-0.01211886]\n",
      " [ 0.01200168]\n",
      " [ 0.01415832]\n",
      " [-0.01451897]]\n",
      "[[-0.01083975]\n",
      " [ 0.01077697]\n",
      " [ 0.012621  ]\n",
      " [-0.0129714 ]]\n",
      "[[-0.00987758]\n",
      " [ 0.00985406]\n",
      " [ 0.011469  ]\n",
      " [-0.01181104]]\n",
      "[[-0.00912145]\n",
      " [ 0.00912747]\n",
      " [ 0.01056649]\n",
      " [-0.01090134]]\n",
      "[[-0.00850788]\n",
      " [ 0.0085368 ]\n",
      " [ 0.00983602]\n",
      " [-0.01016452]]\n",
      "[[ 0.00799761]\n",
      " [ 0.99195527]\n",
      " [ 0.99077013]\n",
      " [ 0.00955264]]\n",
      "Layer 0:\n",
      "[[ 0.95686602 -6.05247567  5.473298    1.75891924 -3.07118592  1.25046143]\n",
      " [-2.72781871 -5.64285032 -4.50652517 -2.88898525 -3.7403061  -2.54093422]\n",
      " [-0.09123591  2.31909978  2.4112387  -0.85533304  5.18432584 -0.50637394]]\n",
      "\n",
      "Layer 1:\n",
      "[[ 3.05264146]\n",
      " [-9.18576988]\n",
      " [-7.10714627]\n",
      " [ 3.0159911 ]\n",
      " [ 6.8802426 ]\n",
      " [ 2.3037127 ]]\n"
     ]
    }
   ],
   "source": [
    "n = Network(inputs, hidden, outputs)\n",
    "n.train(X, y)\n",
    "print(n.run(X))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
